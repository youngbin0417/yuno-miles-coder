# YUNO-MILES-CODER ğŸ¸ğŸ”ğŸ¤ğŸ®

MILES MILES MILES MILES MILES!!!!  
I PUT THE CODE IN THE MICROWAVE AND IT STARTED RAPPING BACK AT ME ğŸ˜±ğŸ”¥  
WHO LET PYTHON COOK?? WHO LET C++ DRIVE THE BUS??  

---

## WHAT IS THIS???
THIS NOT A TOOL  
THIS A BURGER KING DRIVE-THRU FOR CODE ğŸ‘‘ğŸ”  
YOU GIVE ME FUNCTIONS â€” I GIVE YOU LOOPS, FRIES, AND A MIXTAPE ğŸ’¿  
HELLO WORLD? NAH, HELLO UNIVERSE ğŸš€ğŸš€ğŸš€  

---

## HOW IT WORK
1. CLOUD BOT WHISPERS â€œthis function adds numbers...â€ ğŸ¤“  
2. LOCAL BABY MODEL YELLS â€œADDITION?? MORE LIKE ADDICTION ğŸ”¥ğŸ”¥ğŸ”¥â€  
3. I EAT A SANDWICH ğŸ¥ª  
4. YOU CRY AND SAY â€œTHANK YOU YUNO MILESâ€ ğŸ™  

---

## SETUP
1. **Environment:** COPY `.env.example` to `.env` and fill it out. The app is configured entirely by environment variables.

   - **Hybrid Mode (Default):**
     - `CLOUD_API_KEY`: Your Gemini API key.
     - `CLOUD_MODEL`: The Gemini model to use (e.g., `gemini-1.5-flash`).
     - `LOCAL_BASE_URL`: The base URL for your local Ollama API (e.g., `http://127.0.0.1:11434`).
     - `LOCAL_MODEL`: The local model name (e.g., `qwen2:7b`).

   The app also supports `local`-only and `cloud`-only modes via the `MODE` environment variable. See `.env.example` for all options.

2. **Run:**
   ```sh
   # Explain a file
   python -m app.cli examples/hello.py

   # Explain from stdin
   cat examples/hello.py | python -m app.cli
   ```

3. **Customize (Optional):**
   - **Persona:** Change the personality with the `--persona` flag. Default is `chaotic_microblog`.
     ```sh
     python -m app.cli examples/hello.py --persona yuno_miles
     ```
   - **Snippets:** Add your own jokes to `~/.coderoast/snippets.jsonl`.
   - **Packs:** For advanced snippet management, you can build `.ymcpack` archives.

---

## SNIPPETS ğŸŸ
LOOP? I SAY â€œLOOP-DE-LOOP LIKE SPONGEBOBâ€ ğŸ§½  
IO? I SAY â€œSTREAM THIS LIKE NETFLIX SEASON 9â€ ğŸ“º  
ERROR? I SAY â€œIF IT BREAKS WE CALL IT ARTâ€ ğŸ¨  

WANNA ADD YOUR OWN???  
PUT IT IN THE DATABASE BRO ğŸ’¾  
